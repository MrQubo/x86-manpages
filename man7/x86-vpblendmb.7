'\" t
.nh
.TH "X86-VPBLENDMB-VPBLENDMW" "7" "December 2023" "Intel" "Intel x86-64 ISA Manual"
.SH NAME
VPBLENDMB-VPBLENDMW - BLEND BYTE-WORD VECTORS USING AN OPMASK CONTROL
.TS
allbox;
l l l l l 
l l l l l .
\fBOpcode/Instruction\fP	\fBOp/En\fP	\fB64/32 bit Mode Support\fP	\fBCPUID Feature Flag\fP	\fBDescription\fP
T{
EVEX.128.66.0F38.W0 66 /r VPBLENDMB xmm1 {k1}{z}, xmm2, xmm3/m128
T}	A	V/V	AVX512VL AVX512BW	T{
Blend byte integer vector xmm2 and byte vector xmm3/m128 and store the result in xmm1, under control mask.
T}
T{
EVEX.256.66.0F38.W0 66 /r VPBLENDMB ymm1 {k1}{z}, ymm2, ymm3/m256
T}	A	V/V	AVX512VL AVX512BW	T{
Blend byte integer vector ymm2 and byte vector ymm3/m256 and store the result in ymm1, under control mask.
T}
T{
EVEX.512.66.0F38.W0 66 /r VPBLENDMB zmm1 {k1}{z}, zmm2, zmm3/m512
T}	A	V/V	AVX512BW	T{
Blend byte integer vector zmm2 and byte vector zmm3/m512 and store the result in zmm1, under control mask.
T}
T{
EVEX.128.66.0F38.W1 66 /r VPBLENDMW xmm1 {k1}{z}, xmm2, xmm3/m128
T}	A	V/V	AVX512VL AVX512BW	T{
Blend word integer vector xmm2 and word vector xmm3/m128 and store the result in xmm1, under control mask.
T}
T{
EVEX.256.66.0F38.W1 66 /r VPBLENDMW ymm1 {k1}{z}, ymm2, ymm3/m256
T}	A	V/V	AVX512VL AVX512BW	T{
Blend word integer vector ymm2 and word vector ymm3/m256 and store the result in ymm1, under control mask.
T}
T{
EVEX.512.66.0F38.W1 66 /r VPBLENDMW zmm1 {k1}{z}, zmm2, zmm3/m512
T}	A	V/V	AVX512BW	T{
Blend word integer vector zmm2 and word vector zmm3/m512 and store the result in zmm1, under control mask.
T}
.TE

.SH INSTRUCTION OPERAND ENCODING  href="./vpblendmb:vpblendmw.html#instruction-operand-encoding"
class="anchor">¶

.TS
allbox;
l l l l l l 
l l l l l l .
\fBOp/En\fP	\fBTuple Type\fP	\fBOperand 1\fP	\fBOperand 2\fP	\fBOperand 3\fP	\fBOperand 4\fP
A	Full Mem	ModRM:reg (w)	EVEX.vvvv (r)	ModRM:r/m (r)	N/A
.TE

.SS DESCRIPTION
Performs an element-by-element blending of byte/word elements between
the first source operand byte vector register and the second source
operand byte vector from memory or register, using the instruction mask
as selector. The result is written into the destination byte vector
register.

.PP
The destination and first source operands are ZMM/YMM/XMM registers. The
second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit
memory location or a 512/256/128-bit memory location.

.PP
The mask is not used as a writemask for this instruction. Instead, the
mask is used as an element selector: every element of the destination is
conditionally selected between first source or second source using the
value of the related mask bit (0 for first source, 1 for second source).

.SS OPERATION
.SS VPBLENDMB (EVEX ENCODED VERSIONS)  href="./vpblendmb:vpblendmw.html#vpblendmb--evex-encoded-versions-"
class="anchor">¶

.EX
(KL, VL) = (16, 128), (32, 256), (64, 512)
FOR j := 0 TO KL-1
    i := j * 8
    IF k1[j] OR *no writemask*
        THEN DEST[i+7:i] := SRC2[i+7:i]
        ELSE
            IF *merging-masking*
                        ; merging-masking
                THEN DEST[i+7:i] := SRC1[i+7:i]
                ELSE
                        ; zeroing-masking
                    DEST[i+7:i] := 0
            FI;
    FI;
ENDFOR
DEST[MAXVL-1:VL] := 0;
.EE

.SS VPBLENDMW (EVEX ENCODED VERSIONS)  href="./vpblendmb:vpblendmw.html#vpblendmw--evex-encoded-versions-"
class="anchor">¶

.EX
(KL, VL) = (8, 128), (16, 256), (32, 512)
FOR j := 0 TO KL-1
    i := j * 16
    IF k1[j] OR *no writemask*
        THEN DEST[i+15:i] := SRC2[i+15:i]
        ELSE
            IF *merging-masking*
                THEN DEST[i+15:i] := SRC1[i+15:i]
                ELSE ; zeroing-masking
                    DEST[i+15:i] := 0
            FI;
    FI;
ENDFOR
DEST[MAXVL-1:VL] := 0
.EE

.SS INTEL C/C++ COMPILER INTRINSIC EQUIVALENT <a
href="./vpblendmb:vpblendmw.html#intel-c-c++-compiler-intrinsic-equivalent"
class="anchor">¶

.EX
VPBLENDMB __m512i _mm512_mask_blend_epi8(__mmask64 m, __m512i a, __m512i b);

VPBLENDMB __m256i _mm256_mask_blend_epi8(__mmask32 m, __m256i a, __m256i b);

VPBLENDMB __m128i _mm_mask_blend_epi8(__mmask16 m, __m128i a, __m128i b);

VPBLENDMW __m512i _mm512_mask_blend_epi16(__mmask32 m, __m512i a, __m512i b);

VPBLENDMW __m256i _mm256_mask_blend_epi16(__mmask16 m, __m256i a, __m256i b);

VPBLENDMW __m128i _mm_mask_blend_epi16(__mmask8 m, __m128i a, __m128i b);
.EE

.SS SIMD FLOATING-POINT EXCEPTIONS  href="./vpblendmb:vpblendmw.html#simd-floating-point-exceptions"
class="anchor">¶

.PP
None

.SS OTHER EXCEPTIONS  href="./vpblendmb:vpblendmw.html#other-exceptions"
class="anchor">¶

.PP
See Table 2-49, “Type E4 Class
Exception Conditions.”

.SH COLOPHON
This UNOFFICIAL, mechanically-separated, non-verified reference is
provided for convenience, but it may be
incomplete or
broken in various obvious or non-obvious ways.
Refer to Intel® 64 and IA-32 Architectures Software Developer’s
Manual
\[la]https://software.intel.com/en\-us/download/intel\-64\-and\-ia\-32\-architectures\-sdm\-combined\-volumes\-1\-2a\-2b\-2c\-2d\-3a\-3b\-3c\-3d\-and\-4\[ra]
for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/MrQubo/x86-manpages.
