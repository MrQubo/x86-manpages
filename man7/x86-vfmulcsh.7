'\" t
.nh
.TH "X86-VFCMULCSH-VFMULCSH" "7" "December 2023" "Intel" "Intel x86-64 ISA Manual"
.SH NAME
VFCMULCSH-VFMULCSH - COMPLEX MULTIPLY SCALAR FP16 VALUES
.TS
allbox;
l l l l l 
l l l l l .
\fBInstruction En Bit Mode Flag Support Instruction En Bit Mode Flag Support 64/32 CPUID Feature Instruction En Bit Mode Flag CPUID Feature Instruction En Bit Mode Flag Op/ 64/32 CPUID Feature Instruction En Bit Mode Flag 64/32 CPUID Feature Instruction En Bit Mode Flag CPUID Feature Instruction En Bit Mode Flag Op/ 64/32 CPUID Feature\fP	\fB\fP	\fBSupport\fP	\fB\fP	\fBDescription\fP
T{
EVEX.LLIG.F2.MAP6.W0 D7 /r VFCMULCSH xmm1{k1}{z}, xmm2, xmm3/m32 {er}
T}	A	V/V	AVX512-FP16	T{
Complex multiply a pair of FP16 values from xmm2 and complex conjugate of xmm3/m32, and store the result in xmm1 subject to writemask k1. Bits 127:32 of xmm2 are copied to xmm1[127:32]\&.
T}
T{
EVEX.LLIG.F3.MAP6.W0 D7 /r VFMULCSH xmm1{k1}{z}, xmm2, xmm3/m32 {er}
T}	A	V/V	AVX512-FP16	T{
Complex multiply a pair of FP16 values from xmm2 and xmm3/m32, and store the result in xmm1 subject to writemask k1. Bits 127:32 of xmm2 are copied to xmm1[127:32]\&.
T}
.TE

.SH INSTRUCTION OPERAND ENCODING  href="./vfcmulcsh:vfmulcsh.html#instruction-operand-encoding"
class="anchor">¶

.TS
allbox;
l l l l l l 
l l l l l l .
\fBOp/En\fP	\fBTuple\fP	\fBOperand 1\fP	\fBOperand 2\fP	\fBOperand 3\fP	\fBOperand 4\fP
A	Scalar	ModRM:reg (w)	VEX.vvvv (r)	ModRM:r/m (r)	N/A
.TE

.SS DESCRIPTION
This instruction performs a complex multiply operation. There are normal
and complex conjugate forms of the operation. The masking for this
operation is done on 32-bit quantities representing a pair of FP16
values.

.PP
Bits 127:32 of the destination operand are copied from the corresponding
bits of the first source operand. Bits MAXVL-1:128 of the destination
operand are zeroed. The low FP16 element of the destination is updated
according to the writemask.

.PP
Rounding is performed at every FMA (fused multiply and add) boundary.
Execution occurs as if all MXCSR exceptions are masked. MXCSR status
bits are updated to reflect exceptional conditions.

.SS OPERATION
.SS VFCMULCSH DEST{K1}, SRC1, SRC2 (AVX512) <a
href="./vfcmulcsh:vfmulcsh.html#vfcmulcsh-dest-k1---src1--src2--avx512-"
class="anchor">¶

.EX
KL := VL / 32
IF k1[0] or *no writemask*:
    tmp.fp16[0] := src1.fp16[0] * src2.fp16[0]
    tmp.fp16[1] := src1.fp16[1] * src2.fp16[0]
    // conjugate version subtracts odd final term
    dest.fp16[0] := tmp.fp16[0] + src1.fp16[1] * src2.fp16[1]
    dest.fp16[1] := tmp.fp16[1] - src1.fp16[0] * src2.fp16[1]
ELSE IF *zeroing*:
    dest.fp16[0] := 0
    dest.fp16[1] := 0
DEST[127:32] := src1[127:32] // copy upper part of src1
DEST[MAXVL-1:128] := 0
.EE

.SS VFMULCSH DEST{K1}, SRC1, SRC2 (AVX512) <a
href="./vfcmulcsh:vfmulcsh.html#vfmulcsh-dest-k1---src1--src2--avx512-"
class="anchor">¶

.EX
KL := VL / 32
IF k1[0] or *no writemask*:
    // non-conjugate version subtracts last even term
    tmp.fp16[0] := src1.fp16[0] * src2.fp16[0]
    tmp.fp16[1] := src1.fp16[1] * src2.fp16[0]
    dest.fp16[0] := tmp.fp16[0] - src1.fp16[1] * src2.fp16[1]
    dest.fp16[1] := tmp.fp16[1] + src1.fp16[0] * src2.fp16[1]
ELSE IF *zeroing*:
    dest.fp16[0] := 0
    dest.fp16[1] := 0
DEST[127:32] := src1[127:32] // copy upper part of src1
DEST[MAXVL-1:128] := 0
.EE

.SS INTEL C/C++ COMPILER INTRINSIC EQUIVALENT <a
href="./vfcmulcsh:vfmulcsh.html#intel-c-c++-compiler-intrinsic-equivalent"
class="anchor">¶

.EX
VFCMULCSH __m128h _mm_cmul_round_sch (__m128h a, __m128h b, const int rounding);

VFCMULCSH __m128h _mm_mask_cmul_round_sch (__m128h src, __mmask8 k, __m128h a, __m128h b, const int rounding);

VFCMULCSH __m128h _mm_maskz_cmul_round_sch (__mmask8 k, __m128h a, __m128h b, const int rounding);

VFCMULCSH __m128h _mm_cmul_sch (__m128h a, __m128h b);

VFCMULCSH __m128h _mm_mask_cmul_sch (__m128h src, __mmask8 k, __m128h a, __m128h b);

VFCMULCSH __m128h _mm_maskz_cmul_sch (__mmask8 k, __m128h a, __m128h b);

VFCMULCSH __m128h _mm_fcmul_round_sch (__m128h a, __m128h b, const int rounding);

VFCMULCSH __m128h _mm_mask_fcmul_round_sch (__m128h src, __mmask8 k, __m128h a, __m128h b, const int rounding);

VFCMULCSH __m128h _mm_maskz_fcmul_round_sch (__mmask8 k, __m128h a, __m128h b, const int rounding);

VFCMULCSH __m128h _mm_fcmul_sch (__m128h a, __m128h b);

VFCMULCSH __m128h _mm_mask_fcmul_sch (__m128h src, __mmask8 k, __m128h a, __m128h b);

VFCMULCSH __m128h _mm_maskz_fcmul_sch (__mmask8 k, __m128h a, __m128h b);

VFMULCSH __m128h _mm_fmul_round_sch (__m128h a, __m128h b, const int rounding);

VFMULCSH __m128h _mm_mask_fmul_round_sch (__m128h src, __mmask8 k, __m128h a, __m128h b, const int rounding);

VFMULCSH __m128h _mm_maskz_fmul_round_sch (__mmask8 k, __m128h a, __m128h b, const int rounding);

VFMULCSH __m128h _mm_fmul_sch (__m128h a, __m128h b);

VFMULCSH __m128h _mm_mask_fmul_sch (__m128h src, __mmask8 k, __m128h a, __m128h b);

VFMULCSH __m128h _mm_maskz_fmul_sch (__mmask8 k, __m128h a, __m128h b);

VFMULCSH __m128h _mm_mask_mul_round_sch (__m128h src, __mmask8 k, __m128h a, __m128h b, const int rounding);

VFMULCSH __m128h _mm_maskz_mul_round_sch (__mmask8 k, __m128h a, __m128h b, const int rounding);

VFMULCSH __m128h _mm_mul_round_sch (__m128h a, __m128h b, const int rounding);

VFMULCSH __m128h _mm_mask_mul_sch (__m128h src, __mmask8 k, __m128h a, __m128h b);

VFMULCSH __m128h _mm_maskz_mul_sch (__mmask8 k, __m128h a, __m128h b);

VFMULCSH __m128h _mm_mul_sch (__m128h a, __m128h b);
.EE

.SS SIMD FLOATING-POINT EXCEPTIONS  href="./vfcmulcsh:vfmulcsh.html#simd-floating-point-exceptions"
class="anchor">¶

.PP
Invalid, Underflow, Overflow, Precision, Denormal.

.SS OTHER EXCEPTIONS  href="./vfcmulcsh:vfmulcsh.html#other-exceptions"
class="anchor">¶

.PP
EVEX-encoded instructions, see Table
2-58, “Type E10 Class Exception Conditions.”

.PP
Additionally:

.TS
allbox;
l l 
l l .
\fB\fP	\fB\fP
#UD	If (dest_reg == src1_reg) or (dest_reg == src2_reg).
.TE

.SH COLOPHON
This UNOFFICIAL, mechanically-separated, non-verified reference is
provided for convenience, but it may be
incomplete or
broken in various obvious or non-obvious ways.
Refer to Intel® 64 and IA-32 Architectures Software Developer’s
Manual
\[la]https://software.intel.com/en\-us/download/intel\-64\-and\-ia\-32\-architectures\-sdm\-combined\-volumes\-1\-2a\-2b\-2c\-2d\-3a\-3b\-3c\-3d\-and\-4\[ra]
for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/MrQubo/x86-manpages.
