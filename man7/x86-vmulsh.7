'\" t
.nh
.TH "X86-VMULSH" "7" "December 2023" "Intel" "Intel x86-64 ISA Manual"
.SH NAME
VMULSH - MULTIPLY SCALAR FP16 VALUES
.TS
allbox;
l l l l l 
l l l l l .
\fBInstruction En bit Mode Flag Support Instruction En bit Mode Flag Support 64/32 CPUID Feature Instruction En bit Mode Flag CPUID Feature Instruction En bit Mode Flag Op/ 64/32 CPUID Feature Instruction En bit Mode Flag 64/32 CPUID Feature Instruction En bit Mode Flag CPUID Feature Instruction En bit Mode Flag Op/ 64/32 CPUID Feature\fP	\fB\fP	\fBSupport\fP	\fB\fP	\fBDescription\fP
T{
EVEX.LLIG.F3.MAP5.W0 59 /r VMULSH xmm1{k1}{z}, xmm2, xmm3/m16 {er}
T}	A	V/V	AVX512-FP16	T{
Multiply the low FP16 value in xmm3/m16 by low FP16 value in xmm2, and store the result in xmm1 subject to writemask k1. Bits 127:16 of xmm2 are copied to xmm1[127:16]\&.
T}
.TE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
\fBOp/En\fP	\fBTuple\fP	\fBOperand 1\fP	\fBOperand 2\fP	\fBOperand 3\fP	\fBOperand 4\fP
A	Scalar	ModRM:reg (w)	VEX.vvvv (r)	ModRM:r/m (r)	N/A
.TE

.SS DESCRIPTION
This instruction multiplies the low FP16 value from the source operands
and stores the FP16 result in the destination operand. Bits 127:16 of
the destination operand are copied from the corresponding bits of the
first source operand. Bits MAXVL-1:128 of the destination operand are
zeroed. The low FP16 element of the destination is updated according to
the writemask.

.SS OPERATION
.SS VMULSH (EVEX ENCODED VERSIONS)  href="vmulsh.html#vmulsh--evex-encoded-versions-"
class="anchor">¶

.EX
IF EVEX.b = 1 and SRC2 is a register:
    SET_RM(EVEX.RC)
ELSE
    SET_RM(MXCSR.RC)
IF k1[0] OR *no writemask*:
    DEST.fp16[0] := SRC1.fp16[0] * SRC2.fp16[0]
ELSE IF *zeroing*:
    DEST.fp16[0] := 0
// else dest.fp16[0] remains unchanged
DEST[127:16] := SRC1[127:16]
DEST[MAXVL-1:VL] := 0
.EE

.SS INTEL C/C++ COMPILER INTRINSIC EQUIVALENT  href="vmulsh.html#intel-c-c++-compiler-intrinsic-equivalent"
class="anchor">¶

.EX
VMULSH __m128h _mm_mask_mul_round_sh (__m128h src, __mmask8 k, __m128h a, __m128h b, int rounding);

VMULSH __m128h _mm_maskz_mul_round_sh (__mmask8 k, __m128h a, __m128h b, int rounding);

VMULSH __m128h _mm_mul_round_sh (__m128h a, __m128h b, int rounding);

VMULSH __m128h _mm_mask_mul_sh (__m128h src, __mmask8 k, __m128h a, __m128h b);

VMULSH __m128h _mm_maskz_mul_sh (__mmask8 k, __m128h a, __m128h b);

VMULSH __m128h _mm_mul_sh (__m128h a, __m128h b);
.EE

.SS SIMD FLOATING-POINT EXCEPTIONS  href="vmulsh.html#simd-floating-point-exceptions"
class="anchor">¶

.PP
Invalid, Underflow, Overflow, Precision, Denormal

.SS OTHER EXCEPTIONS
EVEX-encoded instructions, see Table
2-47, “Type E3 Class Exception Conditions.”

.SH COLOPHON
This UNOFFICIAL, mechanically-separated, non-verified reference is
provided for convenience, but it may be
incomplete or
broken in various obvious or non-obvious ways.
Refer to Intel® 64 and IA-32 Architectures Software Developer’s
Manual
\[la]https://software.intel.com/en\-us/download/intel\-64\-and\-ia\-32\-architectures\-sdm\-combined\-volumes\-1\-2a\-2b\-2c\-2d\-3a\-3b\-3c\-3d\-and\-4\[ra]
for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/MrQubo/x86-manpages.
