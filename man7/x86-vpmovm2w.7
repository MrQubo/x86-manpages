'\" t
.nh
.TH "X86-VPMOVM2B-VPMOVM2W-VPMOVM2D-VPMOVM2Q" "7" "December 2023" "Intel" "Intel x86-64 ISA Manual"
.SH NAME
VPMOVM2B-VPMOVM2W-VPMOVM2D-VPMOVM2Q - CONVERT A MASK REGISTER TO A VECTORREGISTER
.TS
allbox;
l l l l l 
l l l l l .
\fBOpcode/Instruction\fP	\fBOp/En\fP	\fB64/32 bit Mode Support\fP	\fBCPUID Feature Flag\fP	\fBDescription\fP
T{
EVEX.128.F3.0F38.W0 28 /r VPMOVM2B xmm1, k1
T}	RM	V/V	AVX512VL AVX512BW	T{
Sets each byte in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
T}
T{
EVEX.256.F3.0F38.W0 28 /r VPMOVM2B ymm1, k1
T}	RM	V/V	AVX512VL AVX512BW	T{
Sets each byte in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
T}
T{
EVEX.512.F3.0F38.W0 28 /r VPMOVM2B zmm1, k1
T}	RM	V/V	AVX512BW	T{
Sets each byte in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
T}
T{
EVEX.128.F3.0F38.W1 28 /r VPMOVM2W xmm1, k1
T}	RM	V/V	AVX512VL AVX512BW	T{
Sets each word in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
T}
T{
EVEX.256.F3.0F38.W1 28 /r VPMOVM2W ymm1, k1
T}	RM	V/V	AVX512VL AVX512BW	T{
Sets each word in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
T}
T{
EVEX.512.F3.0F38.W1 28 /r VPMOVM2W zmm1, k1
T}	RM	V/V	AVX512BW	T{
Sets each word in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
T}
T{
EVEX.128.F3.0F38.W0 38 /r VPMOVM2D xmm1, k1
T}	RM	V/V	AVX512VL AVX512DQ	T{
Sets each doubleword in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
T}
T{
EVEX.256.F3.0F38.W0 38 /r VPMOVM2D ymm1, k1
T}	RM	V/V	AVX512VL AVX512DQ	T{
Sets each doubleword in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
T}
T{
EVEX.512.F3.0F38.W0 38 /r VPMOVM2D zmm1, k1
T}	RM	V/V	AVX512DQ	T{
Sets each doubleword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
T}
T{
EVEX.128.F3.0F38.W1 38 /r VPMOVM2Q xmm1, k1
T}	RM	V/V	AVX512VL AVX512DQ	T{
Sets each quadword in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
T}
T{
EVEX.256.F3.0F38.W1 38 /r VPMOVM2Q ymm1, k1
T}	RM	V/V	AVX512VL AVX512DQ	T{
Sets each quadword in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
T}
T{
EVEX.512.F3.0F38.W1 38 /r VPMOVM2Q zmm1, k1
T}	RM	V/V	AVX512DQ	T{
Sets each quadword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
T}
.TE

.SH INSTRUCTION OPERAND ENCODING <a
href="./vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q.html#instruction-operand-encoding"
class="anchor">¶

.TS
allbox;
l l l l l 
l l l l l .
\fBOp/En\fP	\fBOperand 1\fP	\fBOperand 2\fP	\fBOperand 3\fP	\fBOperand 4\fP
RM	ModRM:reg (w)	ModRM:r/m (r)	N/A	N/A
.TE

.SS DESCRIPTION  href="./vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q.html#description"
class="anchor">¶

.PP
Converts a mask register to a vector register. Each element in the
destination register is set to all 1’s or all 0’s depending on the value
of the corresponding bit in the source mask register.

.PP
The source operand is a mask register. The destination operand is a
ZMM/YMM/XMM register.

.PP
EVEX.vvvv is reserved and must be 1111b otherwise instructions will
#UD.

.SS OPERATION  href="./vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q.html#operation"
class="anchor">¶

.SS VPMOVM2B (EVEX ENCODED VERSIONS) <a
href="./vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q.html#vpmovm2b--evex-encoded-versions-"
class="anchor">¶

.EX
(KL, VL) = (16, 128), (32, 256), (64, 512)
FOR j := 0 TO KL-1
    i := j * 8
    IF SRC[j]
        THEN DEST[i+7:i] := -1
        ELSE DEST[i+7:i] := 0
    FI;
ENDFOR
DEST[MAXVL-1:VL] := 0
.EE

.SS VPMOVM2W (EVEX ENCODED VERSIONS) <a
href="./vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q.html#vpmovm2w--evex-encoded-versions-"
class="anchor">¶

.EX
(KL, VL) = (8, 128), (16, 256), (32, 512)
FOR j := 0 TO KL-1
    i := j * 16
    IF SRC[j]
        THEN DEST[i+15:i] := -1
        ELSE DEST[i+15:i] := 0
    FI;
ENDFOR
DEST[MAXVL-1:VL] := 0
.EE

.SS VPMOVM2D (EVEX ENCODED VERSIONS) <a
href="./vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q.html#vpmovm2d--evex-encoded-versions-"
class="anchor">¶

.EX
(KL, VL) = (4, 128), (8, 256), (16, 512)
FOR j := 0 TO KL-1
    i := j * 32
    IF SRC[j]
        THEN DEST[i+31:i] := -1
        ELSE DEST[i+31:i] := 0
    FI;
ENDFOR
DEST[MAXVL-1:VL] := 0
.EE

.SS VPMOVM2Q (EVEX ENCODED VERSIONS) <a
href="./vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q.html#vpmovm2q--evex-encoded-versions-"
class="anchor">¶

.EX
(KL, VL) = (2, 128), (4, 256), (8, 512)
FOR j := 0 TO KL-1
    i := j * 64
    IF SRC[j]
        THEN DEST[i+63:i] := -1
        ELSE DEST[i+63:i] := 0
    FI;
ENDFOR
DEST[MAXVL-1:VL] := 0
.EE

.SS INTEL C/C++ COMPILER INTRINSIC EQUIVALENTS <a
href="./vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q.html#intel-c-c++-compiler-intrinsic-equivalents"
class="anchor">¶

.EX
VPMOVM2B __m512i _mm512_movm_epi8(__mmask64 );

VPMOVM2D __m512i _mm512_movm_epi32(__mmask8 );

VPMOVM2Q __m512i _mm512_movm_epi64(__mmask16 );

VPMOVM2W __m512i _mm512_movm_epi16(__mmask32 );

VPMOVM2B __m256i _mm256_movm_epi8(__mmask32 );

VPMOVM2D __m256i _mm256_movm_epi32(__mmask8 );

VPMOVM2Q __m256i _mm256_movm_epi64(__mmask8 );

VPMOVM2W __m256i _mm256_movm_epi16(__mmask16 );

VPMOVM2B __m128i _mm_movm_epi8(__mmask16 );

VPMOVM2D __m128i _mm_movm_epi32(__mmask8 );

VPMOVM2Q __m128i _mm_movm_epi64(__mmask8 );

VPMOVM2W __m128i _mm_movm_epi16(__mmask8 );
.EE

.SS SIMD FLOATING-POINT EXCEPTIONS <a
href="./vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q.html#simd-floating-point-exceptions"
class="anchor">¶

.PP
None.

.SS OTHER EXCEPTIONS  href="./vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q.html#other-exceptions"
class="anchor">¶

.PP
EVEX-encoded instruction, see Table
2-55, “Type E7NM Class Exception Conditions.”

.PP
Additionally:

.TS
allbox;
l l 
l l .
\fB\fP	\fB\fP
#UD	If EVEX.vvvv != 1111B.
.TE

.SH COLOPHON
This UNOFFICIAL, mechanically-separated, non-verified reference is
provided for convenience, but it may be
incomplete or
broken in various obvious or non-obvious ways.
Refer to Intel® 64 and IA-32 Architectures Software Developer’s
Manual
\[la]https://software.intel.com/en\-us/download/intel\-64\-and\-ia\-32\-architectures\-sdm\-combined\-volumes\-1\-2a\-2b\-2c\-2d\-3a\-3b\-3c\-3d\-and\-4\[ra]
for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/MrQubo/x86-manpages.
